{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a82b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcav/miniconda3/envs/unsup-mono-depth/lib/python3.8/site-packages/torch/cuda/__init__.py:79: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint..\n",
      "Initializing samples..\n"
     ]
    }
   ],
   "source": [
    "from trainer import *\n",
    "\n",
    "with open('configs/test_config.yaml') as file:\n",
    "    config = yaml.full_load(file)\n",
    " \n",
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf752af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trainer.dataset\n",
    "batch   = next(iter(trainer.train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f891d9",
   "metadata": {},
   "source": [
    "# Create a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb614ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_img  = batch['tgt']         # [b, 3, H, W]\n",
    "ref_imgs = batch['ref_imgs']    # [[b, 3, H, W], [b, 3, H, W]]\n",
    "K        = batch['intrinsics']  # [b, 3, 4]\n",
    "depth    = batch['groundtruth'] # [b, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbae457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0368, -0.0061, -3.0574,  0.9661,  0.0742, -0.0188],\n",
       "        [ 0.0295,  0.0196,  2.6650,  0.5989, -0.3135, -0.0055],\n",
       "        [-0.0064,  0.0139,  2.1024, -0.0079,  0.0057,  0.0032],\n",
       "        [ 0.0275,  0.0673,  3.0010,  1.1015, -0.1613,  0.0574]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose = batch['oxts']\n",
    "pose[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767953b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c85195df",
   "metadata": {},
   "source": [
    "# The Inverse Warp\n",
    "\n",
    "The goal is to create a target image by transforming source images. But to get around splatting, we have to:\n",
    "\n",
    "1. Transform target to source\n",
    "2. As transformed pixels are continuous, use bilinear sampling (differentiable) to sample from source images.\n",
    "3. As we know which pixel in target corresponds to which \"transformed-and-sampled\" source image we can create a target image.\n",
    "\n",
    "### Resources\n",
    "- [X] https://www.youtube.com/watch?v=lNYhWBPEeaY&list=PLyqSpQzTE6M-T5ZrthkU763MHKIKCa0sX&index=7\n",
    "- [X] https://github.com/nianticlabs/monodepth2/issues/87\n",
    "- [ ] https://www.cse.huji.ac.il/course/2006/impr/lectures2006/Tirgul8_LK.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d52958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshgrid(B, H, W, dtype, device, normalized=False):\n",
    "    \"\"\"\n",
    "    Create meshgrid with a specific resolution\n",
    "    Parameters\n",
    "    ----------\n",
    "    B : int\n",
    "        Batch size\n",
    "    H : int\n",
    "        Height size\n",
    "    W : int\n",
    "        Width size\n",
    "    dtype : torch.dtype\n",
    "        Meshgrid type\n",
    "    device : torch.device\n",
    "        Meshgrid device\n",
    "    normalized : bool\n",
    "        True if grid is normalized between -1 and 1\n",
    "    Returns\n",
    "    -------\n",
    "    xs : torch.Tensor [B,1,W]\n",
    "        Meshgrid in dimension x\n",
    "    ys : torch.Tensor [B,H,1]\n",
    "        Meshgrid in dimension y\n",
    "    \"\"\"\n",
    "    if normalized:\n",
    "        xs = torch.linspace(-1, 1, W, device=device, dtype=dtype)\n",
    "        ys = torch.linspace(-1, 1, H, device=device, dtype=dtype)\n",
    "    else:\n",
    "        xs = torch.linspace(0, W-1, W, device=device, dtype=dtype)\n",
    "        ys = torch.linspace(0, H-1, H, device=device, dtype=dtype)\n",
    "    ys, xs = torch.meshgrid([ys, xs])\n",
    "    return xs.repeat([B, 1, 1]), ys.repeat([B, 1, 1])\n",
    "\n",
    "def image_grid(B, H, W, dtype, device, normalized=False):\n",
    "    \"\"\"\n",
    "    Create an image grid with a specific resolution\n",
    "    Parameters\n",
    "    ----------\n",
    "    B : int\n",
    "        Batch size\n",
    "    H : int\n",
    "        Height size\n",
    "    W : int\n",
    "        Width size\n",
    "    dtype : torch.dtype\n",
    "        Meshgrid type\n",
    "    device : torch.device\n",
    "        Meshgrid device\n",
    "    normalized : bool\n",
    "        True if grid is normalized between -1 and 1\n",
    "    Returns\n",
    "    -------\n",
    "    grid : torch.Tensor [B,3,H,W]\n",
    "        Image grid containing a meshgrid in x, y and 1\n",
    "    \"\"\"\n",
    "    xs, ys = meshgrid(B, H, W, dtype, device, normalized=normalized)\n",
    "    ones = torch.ones_like(xs)\n",
    "    grid = torch.stack([xs, ys, ones], dim=1)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0904775",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_grid = image_grid(4, depth[0].shape[0], depth[0].shape[1], depth.dtype, depth.device, normalized=False).view(4, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aaa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kinv():\n",
    "    \"\"\"Inverse intrinsics (for lifting)\"\"\"\n",
    "    Kinv = K.clone()\n",
    "    Kinv[:, 0, 0] = 1. / K[:, 0, 0]\n",
    "    Kinv[:, 1, 1] = 1. / K[:, 1, 1]\n",
    "    Kinv[:, 0, 2] = -1. * K[:, 0, 2]/ K[:, 0, 0]\n",
    "    Kinv[:, 1, 2] = -1. * K[:, 1, 2]/ K[:, 1, 1]\n",
    "    return Kinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe11930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0010,  0.0000, -0.7240],\n",
       "         [ 0.0000,  0.0010, -0.2536],\n",
       "         [ 0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0010,  0.0000, -0.7237],\n",
       "         [ 0.0000,  0.0010, -0.2517],\n",
       "         [ 0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0010,  0.0000, -0.7252],\n",
       "         [ 0.0000,  0.0011, -0.2506],\n",
       "         [ 0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0010,  0.0000, -0.7237],\n",
       "         [ 0.0000,  0.0010, -0.2517],\n",
       "         [ 0.0000,  0.0000,  1.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kinv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a382e8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0010,  0.0000, -0.7240],\n",
       "         [ 0.0000,  0.0010, -0.2536],\n",
       "         [ 0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0010,  0.0000, -0.7237],\n",
       "         [ 0.0000,  0.0010, -0.2517],\n",
       "         [ 0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0010,  0.0000, -0.7252],\n",
       "         [ 0.0000,  0.0011, -0.2506],\n",
       "         [ 0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.0010,  0.0000, -0.7237],\n",
       "         [ 0.0000,  0.0010, -0.2517],\n",
       "         [ 0.0000,  0.0000,  1.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[..., :3, :3].inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ecfc894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[959.1977,   0.0000, 694.4383],\n",
       "         [  0.0000, 952.9324, 241.6793],\n",
       "         [  0.0000,   0.0000,   1.0000]],\n",
       "\n",
       "        [[960.1149,   0.0000, 694.7923],\n",
       "         [  0.0000, 954.8911, 240.3547],\n",
       "         [  0.0000,   0.0000,   1.0000]],\n",
       "\n",
       "        [[956.9475,   0.0000, 693.9767],\n",
       "         [  0.0000, 952.2352, 238.6081],\n",
       "         [  0.0000,   0.0000,   1.0000]],\n",
       "\n",
       "        [[960.1149,   0.0000, 694.7923],\n",
       "         [  0.0000, 954.8911, 240.3547],\n",
       "         [  0.0000,   0.0000,   1.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5619990",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'bmm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14270/1788638097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Estimate the outward rays in the camera frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKinv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Scale rays to metric depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxnorm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'bmm'"
     ]
    }
   ],
   "source": [
    "# Estimate the outward rays in the camera frame\n",
    "xnorm = (Kinv.bmm(flat_grid)).view(B, 3, H, W)\n",
    "# Scale rays to metric depth\n",
    "Xc = xnorm * depth\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
